{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdfU3UNutn+fHkUaM6pBuQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshavalmiki/258-Deep-learning/blob/main/A5_Part2__Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part B - Pytorch\n",
        "\n",
        "Create a 3 layer neural network.\n",
        "use einsum.\n",
        "Use 3 variables based on non-linear equation.\n",
        "Generate syntetic data using the equationand 4-d plot in matplotlib.\n",
        "\n",
        "References Used\n",
        "Tensors Fundamentals and PyTorch\n",
        "deep_learning_fundamentals_part1.ipynb\n"
      ],
      "metadata": {
        "id": "9DiLYqIu8whF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uWdrVvf8Sin9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate_data() function is defined to generate synthetic data. It creates input features x randomly sampled from a uniform distribution\n"
      ],
      "metadata": {
        "id": "yjZQYweWaaaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_data() function for classification\n",
        "def generate_data(num_samples):\n",
        "    x = np.random.uniform(-1, 1, (num_samples, 3))\n",
        "    weights_true = np.array([[2, -1, 0.5], [1, 2, -1], [-1, 1.5, 2]])\n",
        "    bias_true = np.array([0.5, -1, 1])\n",
        "    y_true = np.argmax(x @ weights_true + bias_true, axis=1)  # Classification labels\n",
        "    return torch.from_numpy(x).float(), torch.from_numpy(y_true).long()\n"
      ],
      "metadata": {
        "id": "cIkoIou5Sjzu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " A custom dataset class CustomDataset is defined to encapsulate the input features and target values.\n",
        ""
      ],
      "metadata": {
        "id": "68CvSG_aYt06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a custom dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "_BI8SIIFSmvz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 3-layer neural network class named 'Net' is defined using PyTorch's nn.Module. It consists of two hidden layers with ReLU activation and an output layer."
      ],
      "metadata": {
        "id": "MmKmqUIUYyUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified Net class for classification\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden1 = nn.Linear(input_size, hidden_size)\n",
        "        self.hidden2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.hidden1(x))\n",
        "        x = torch.relu(self.hidden2(x))\n",
        "        x = self.output(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "njIjoHkzSo6v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The train() function is defined to handle the training loop. It iterates over the dataset for a specified number of epochs, performs forward and backward propagation, and updates the model parameters using an optimizer."
      ],
      "metadata": {
        "id": "tW1GCF73Y9DX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train(model, dataloader, criterion, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(dataloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(dataloader):.4f}\")\n",
        "    print(\"Training finished.\")"
      ],
      "metadata": {
        "id": "dXOb-OgbSqcZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot_3d() function is defined to visualize the real and predicted data in a 3D scatter plot using Matplotlib."
      ],
      "metadata": {
        "id": "LyF_Hv4xZE2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting function (adjusted to handle 3D output)\n",
        "def plot_3d(x, y, y_pred):\n",
        "    fig = plt.figure(figsize=(12, 6))\n",
        "    # Plot real data\n",
        "    ax1 = fig.add_subplot(121, projection='3d')\n",
        "    ax1.scatter(x[:, 0], x[:, 1], y[:, 0], label='Real - 1st Dim', color='blue')\n",
        "    ax1.scatter(x[:, 0], x[:, 1], y[:, 1], label='Real - 2nd Dim', color='red')\n",
        "    ax1.scatter(x[:, 0], x[:, 1], y[:, 2], label='Real - 3rd Dim', color='green')\n",
        "    ax1.set_title(\"Real Data\")\n",
        "    ax1.legend()\n",
        "    # Plot predicted data\n",
        "    ax2 = fig.add_subplot(122, projection='3d')\n",
        "    ax2.scatter(x[:, 0], x[:, 1], y_pred[:, 0], label='Predicted - 1st Dim', color='blue', alpha=0.5)\n",
        "    ax2.scatter(x[:, 0], x[:, 1], y_pred[:, 1], label='Predicted - 2nd Dim', color='red', alpha=0.5)\n",
        "    ax2.scatter(x[:, 0], x[:, 1], y_pred[:, 2], label='Predicted - 3rd Dim', color='green', alpha=0.5)\n",
        "    ax2.set_title(\"Predicted Data\")\n",
        "    ax2.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bpuvaBm0SuTU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Synthetic Dataset"
      ],
      "metadata": {
        "id": "xEKuYqlQadTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code generates a synthetic dataset using generate_data() and creates a custom dataset and data loader using CustomDataset and torch.utils.data.DataLoader."
      ],
      "metadata": {
        "id": "9GNM6ZFIan7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate synthetic data\n",
        "num_samples = 1000\n",
        "x, y = generate_data(num_samples)\n",
        "\n",
        "# Create a custom dataset and data loader\n",
        "dataset = CustomDataset(x, y)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "Qs3b2BVUQRpG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hyperparameters"
      ],
      "metadata": {
        "id": "Vvn1eqLcajlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Hyperparameters such as **input_size**, **hidden_size**, **output_size**, **number of epochs**, and **learning_rate** are set."
      ],
      "metadata": {
        "id": "Hqo-1lQLZGbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set hyperparameters\n",
        "input_size = 3\n",
        "hidden_size = 64\n",
        "output_size = 3  # 3 to match the 3D output\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01"
      ],
      "metadata": {
        "id": "EByR3AsgVC_N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model, loss function (MSE), and optimizer (Adam) are instantiated."
      ],
      "metadata": {
        "id": "J6dtO464ZsIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model, loss function, and optimizer\n",
        "model = Net(input_size, hidden_size, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "L4bcPPwdVEz_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model is trained using the train function."
      ],
      "metadata": {
        "id": "TREq-u36Zsah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train(model, dataloader, criterion, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjMYLwNvVFxl",
        "outputId": "5ce8f0e9-d8bb-4568-9597-5419fe34c256"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.4067\n",
            "Epoch [2/100], Loss: 0.1014\n",
            "Epoch [3/100], Loss: 0.0615\n",
            "Epoch [4/100], Loss: 0.0775\n",
            "Epoch [5/100], Loss: 0.1151\n",
            "Epoch [6/100], Loss: 0.0688\n",
            "Epoch [7/100], Loss: 0.0529\n",
            "Epoch [8/100], Loss: 0.0582\n",
            "Epoch [9/100], Loss: 0.1081\n",
            "Epoch [10/100], Loss: 0.0786\n",
            "Epoch [11/100], Loss: 0.0442\n",
            "Epoch [12/100], Loss: 0.0383\n",
            "Epoch [13/100], Loss: 0.0427\n",
            "Epoch [14/100], Loss: 0.0423\n",
            "Epoch [15/100], Loss: 0.0440\n",
            "Epoch [16/100], Loss: 0.0377\n",
            "Epoch [17/100], Loss: 0.0757\n",
            "Epoch [18/100], Loss: 0.0664\n",
            "Epoch [19/100], Loss: 0.0500\n",
            "Epoch [20/100], Loss: 0.0594\n",
            "Epoch [21/100], Loss: 0.0463\n",
            "Epoch [22/100], Loss: 0.0360\n",
            "Epoch [23/100], Loss: 0.0317\n",
            "Epoch [24/100], Loss: 0.0375\n",
            "Epoch [25/100], Loss: 0.0738\n",
            "Epoch [26/100], Loss: 0.0417\n",
            "Epoch [27/100], Loss: 0.0818\n",
            "Epoch [28/100], Loss: 0.0482\n",
            "Epoch [29/100], Loss: 0.0365\n",
            "Epoch [30/100], Loss: 0.0318\n",
            "Epoch [31/100], Loss: 0.0245\n",
            "Epoch [32/100], Loss: 0.0316\n",
            "Epoch [33/100], Loss: 0.0252\n",
            "Epoch [34/100], Loss: 0.0236\n",
            "Epoch [35/100], Loss: 0.0255\n",
            "Epoch [36/100], Loss: 0.0393\n",
            "Epoch [37/100], Loss: 0.0910\n",
            "Epoch [38/100], Loss: 0.0347\n",
            "Epoch [39/100], Loss: 0.0424\n",
            "Epoch [40/100], Loss: 0.0615\n",
            "Epoch [41/100], Loss: 0.0281\n",
            "Epoch [42/100], Loss: 0.0593\n",
            "Epoch [43/100], Loss: 0.0267\n",
            "Epoch [44/100], Loss: 0.0296\n",
            "Epoch [45/100], Loss: 0.0175\n",
            "Epoch [46/100], Loss: 0.0203\n",
            "Epoch [47/100], Loss: 0.0534\n",
            "Epoch [48/100], Loss: 0.0363\n",
            "Epoch [49/100], Loss: 0.0240\n",
            "Epoch [50/100], Loss: 0.0193\n",
            "Epoch [51/100], Loss: 0.0543\n",
            "Epoch [52/100], Loss: 0.1559\n",
            "Epoch [53/100], Loss: 0.0473\n",
            "Epoch [54/100], Loss: 0.0379\n",
            "Epoch [55/100], Loss: 0.0294\n",
            "Epoch [56/100], Loss: 0.0368\n",
            "Epoch [57/100], Loss: 0.0286\n",
            "Epoch [58/100], Loss: 0.0624\n",
            "Epoch [59/100], Loss: 0.0427\n",
            "Epoch [60/100], Loss: 0.0429\n",
            "Epoch [61/100], Loss: 0.0350\n",
            "Epoch [62/100], Loss: 0.0316\n",
            "Epoch [63/100], Loss: 0.0233\n",
            "Epoch [64/100], Loss: 0.0379\n",
            "Epoch [65/100], Loss: 0.0224\n",
            "Epoch [66/100], Loss: 0.0288\n",
            "Epoch [67/100], Loss: 0.0345\n",
            "Epoch [68/100], Loss: 0.0845\n",
            "Epoch [69/100], Loss: 0.0363\n",
            "Epoch [70/100], Loss: 0.0211\n",
            "Epoch [71/100], Loss: 0.0285\n",
            "Epoch [72/100], Loss: 0.0303\n",
            "Epoch [73/100], Loss: 0.0206\n",
            "Epoch [74/100], Loss: 0.0244\n",
            "Epoch [75/100], Loss: 0.0248\n",
            "Epoch [76/100], Loss: 0.0409\n",
            "Epoch [77/100], Loss: 0.0283\n",
            "Epoch [78/100], Loss: 0.0275\n",
            "Epoch [79/100], Loss: 0.0559\n",
            "Epoch [80/100], Loss: 0.0428\n",
            "Epoch [81/100], Loss: 0.0254\n",
            "Epoch [82/100], Loss: 0.0205\n",
            "Epoch [83/100], Loss: 0.0238\n",
            "Epoch [84/100], Loss: 0.0762\n",
            "Epoch [85/100], Loss: 0.0249\n",
            "Epoch [86/100], Loss: 0.0298\n",
            "Epoch [87/100], Loss: 0.0303\n",
            "Epoch [88/100], Loss: 0.0246\n",
            "Epoch [89/100], Loss: 0.0238\n",
            "Epoch [90/100], Loss: 0.0223\n",
            "Epoch [91/100], Loss: 0.0346\n",
            "Epoch [92/100], Loss: 0.0280\n",
            "Epoch [93/100], Loss: 0.0419\n",
            "Epoch [94/100], Loss: 0.0392\n",
            "Epoch [95/100], Loss: 0.0333\n",
            "Epoch [96/100], Loss: 0.0263\n",
            "Epoch [97/100], Loss: 0.0596\n",
            "Epoch [98/100], Loss: 0.0211\n",
            "Epoch [99/100], Loss: 0.0359\n",
            "Epoch [100/100], Loss: 0.0257\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "WrFv9uKWazbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    test_data = x\n",
        "    predicted = model(test_data).numpy()"
      ],
      "metadata": {
        "id": "TdDA5XiHVJOO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Visualization"
      ],
      "metadata": {
        "id": "a6wo4IwZa1ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the plotting function to visualize decision boundaries\n",
        "def plot_decision_boundaries(model, x):\n",
        "    x1_range = np.linspace(-1, 1, 100)\n",
        "    x2_range = np.linspace(-1, 1, 100)\n",
        "    X1, X2 = np.meshgrid(x1_range, x2_range)\n",
        "    grid = np.column_stack((X1.ravel(), X2.ravel(), np.zeros_like(X1.ravel())))  # Generate grid points\n",
        "    with torch.no_grad():\n",
        "        predictions = model(torch.from_numpy(grid).float())\n",
        "        pred_labels = torch.argmax(predictions, dim=1).numpy().reshape(X1.shape)\n",
        "    plt.contourf(X1, X2, pred_labels, alpha=0.3, cmap='viridis')\n",
        "    plt.scatter(x[:, 0], x[:, 1], c=y, cmap='viridis')\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.title('Decision Boundaries')\n",
        "    plt.colorbar(label='Class')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4Dz_ZaYo6p5y"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}
